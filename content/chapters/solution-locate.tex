\chapter{The \locate* step}
\label{chap:locate}

\newcommand{\locateimgsize}{0.9\textwidth}

The task of the \locate* step consists in extracting the positions of the bubbles in pixel coordinates, independently for each frame of each camera.

\section{State of the art}

When searching in literature, many approaches were found to tackle the \locate* problem.
They were tested and compared with the algorithmic ideas developed within this thesis:
\begin{itemize}
	\itemsep 0em
	\item Section~\ref{sec:locate:trackpy} explores the Trackpy~\cite{trackpy} Python library;
	\item Section~\ref{sec:locate:myptv} explores the MyPTV~\cite{myptv} Python library;
	\item Section~\ref{sec:locate:tractrac} explores the TracTrac~\cite{tractrac} Python program;
	\item Section~\ref{sec:locate:fourdptv} explores the 4d-ptv~\cite{fourdptv} Matlab script.
\end{itemize}

\section{Requirements}

\subsection{Input}
The \locate* step receives as input the videos captured by the cameras, frame by frame.
The images are pre-processed by an FPGA included in the cameras: the background is removed, and the resulting image is binarized with a threshold, to have distinct white bubbles over a black background.
Figure~\ref{fig:locate:original} depicts an example input frame.

\begin{figure}
	\centerline{\includegraphics[width=\locateimgsize]{images/locate/_original-frame-full.png}}
	\caption{\centering An example of frame returned by the cameras}
	\label{fig:locate:original}
\end{figure}

\subsection{Output}
\label{sec:locate:output}

The output of the \locate* step is a couple of \texttt{numpy} arrays.
An array called \texttt{positions} describes the coordinates of each bubble present in a frame.
It is a four-dimensional, floating-point array, where \texttt{positions[C][F][B]} describes the $B$-th bubble of the $F$-th frame of camera $C$, in the form of an \texttt{(x, y[, area])} tuple.
Bubbles are ordered in a random, arbitrary way for each frame: there is no correlation between two bubbles with the same $B$ but different $C$ and/or $F$.

Due to \texttt{numpy} limitations, the array is pre-allocated of a fixed size: while the number of cameras is fixed, an upper limit on the number of frames and bubbles must be decided before execution.
Knowing which frames contain meaningful data is trivial, while it is not for the number of bubbles, that can change between frame and frame.
For this reason, a second array was introduced: \texttt{numTracers} is a two-dimensional, integer array.
\texttt{numTracers[C][F]} carries the information of how many tracers are valid inside the $F$-th frame of camera $C$.
The coordinates of the valid tracers will therefore be \texttt{positions[C][F][numTracers[C][F]]}.

\subsection{Speed}

When used on a setup of $N$ cameras with frame rate $f$ each, the \locate* step would receive $N{\cdot}f$ independent frames each second.
To respect the real-time constraint, the \locate* step would therefore need to operate at a minimum of $N{\cdot}f$ FPS.

When I did the analysis on the \locate* step, the plan was to have 3 cameras working at 30 FPS, requiring a 90 FPS \locate* step.
Later, the cameras turned out to be slower, at 24 FPS, but there were 4: the final \locate* implementation was able to manage also these 96 FPS.

\subsection{Quality}

Ideally, all tracers should be detected, since errors in the locating process would propagate to future steps:
\begin{itemize}
	\itemsep 0em
	\item \textbf{False positives}: the \match* phase will have more candidates, leading to \textit{possible} wrong reconstructions: the \match* can both choose the correct bubble, or the one added by the error (or another real one);
	\item \textbf{False negatives:} the same bubble in another frame will not have the correct match, leading to \textit{certain} wrong reconstructions.
\end{itemize}
As such, it is better to overpredict (false positives) than to miss bubbles.

It is however to be noted that the most important requirement is the speed: a worse implementation which is speedwise above target should be preferred to a better implementation that does not meet speed requirements.

\section{Approaches}
\label{sec:locate:approaches}

The following sections describe the many different approaches evaluated for the \locate* step.
Their speed and quality is compared on a common 1-camera, 100-frame sequence.
Each approach reports an example frame: it is the result of performing the \locate* on figure~\ref{fig:locate:original-crop}, which itself is a portion of the frame in figure~\ref{fig:locate:original}.

\begin{figure}[H]
	\centerline{\includegraphics[width=\locateimgsize]{images/locate/_original-frame.png}}
	\caption{\centering The portion of figure~\ref{fig:locate:original} used to display the locate result}
	\label{fig:locate:original-crop}
\end{figure}


\newpage
\input{content/chapters/solution-locate/trackpy.tex} \newpage
\input{content/chapters/solution-locate/trackpy-cupy.tex} \newpage
\input{content/chapters/solution-locate/CNN.tex} \newpage
\input{content/chapters/solution-locate/torch.unfold.tex} \newpage
\input{content/chapters/solution-locate/myptv.tex} \newpage
\input{content/chapters/solution-locate/gpu-algorithm.tex} \newpage
\input{content/chapters/solution-locate/iterative.tex} \newpage
\input{content/chapters/solution-locate/tractrac.tex} \newpage
\input{content/chapters/solution-locate/hough.tex} \newpage
\input{content/chapters/solution-locate/hough-gpu.tex} \newpage
\input{content/chapters/solution-locate/4dptv.tex} \newpage
\input{content/chapters/solution-locate/moments.tex} \newpage
\input{content/chapters/solution-locate/moments-gpu.tex} \newpage

\section{Final choice}

All the previously described approaches were compared among each other and with the target speed.
As visible in figure~\ref{fig:locate:speed}, none of the approaches was able to reach the target 90 FPS.
Since no other approach or idea was available, the fastest algorithm (GPU moments, described in section~\ref{sec:locate:gpu-moments}) was chosen.
Incidentally, the selected algorithm was also one of the best in terms of output quality.

\begin{figure}
	\centerline{\includegraphics[width=\textwidth]{images/locate-speed-comparison.png}}
	\caption{\centering Performance evaluation of different approaches for the \locate* step}
	\label{fig:locate:speed}
\end{figure}

To compare the different approaches with each other, some modifications were required to ensure consistency, for simpler comparison.
After choosing the final algorithm, it was implemented again from scratch, in order to make it as fast as possible, with no overhead.
This resulted in a decent speedup, which enabled the algorithm to execute at 102 FPS, faster than the target speed, as visible in figure~\ref{fig:locate:speed-cleansheet}.

\begin{figure}
	\centerline{\includegraphics[width=\textwidth]{images/locate-cleansheet-speed.png}}
	\caption{\centering Computation speed of the chosen \locate* algorithm before and after the re-implementation, compared with the target speed}
	\label{fig:locate:speed-cleansheet}
\end{figure}
